{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP+A6n8ojRS9k+k9bERmwc7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rakshitha149/NLP-AD/blob/main/13_03_25.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "23bZS_cVWvZq"
      },
      "outputs": [],
      "source": [
        "import google.generativeai as genai\n",
        "\n",
        "from google.colab import userdata\n",
        "\n",
        "GOOGLE_API_KEY=userdata.get('GOOGLE_API_KEY')\n",
        "\n",
        "genai.configure(api_key=GOOGLE_API_KEY)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pathlib\n",
        "\n",
        "import textwrap\n",
        "\n",
        "from IPython.display import display, Markdown\n",
        "\n",
        "def to_markdown(text):\n",
        "\n",
        "  text = text.replace('•', '  *')\n",
        "\n",
        "  return Markdown(textwrap.indent(text, '> ', predicate=lambda _: True))\n"
      ],
      "metadata": {
        "id": "yupW90zKWybH"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import PIL.Image\n",
        "img = PIL.Image.open('/content/INTERVIEW SKILLS.png')\n",
        "imgmodel = genai.GenerativeModel('gemini-1.5-flash')\n",
        "model = genai.GenerativeModel('gemini-1.5-flash')\n",
        "response = model.generate_content([\"Write a short, engaging blog post based on this picture.It should include a description of the meal in the photo and talk about my journey meal prepping.\", img],stream=True)\n",
        "response.resolve()"
      ],
      "metadata": {
        "id": "0NZhHXoCWyfP"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "to_markdown(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        },
        "id": "lqh7IBTcWyj9",
        "outputId": "f34e0060-fcc3-4cf9-f0f2-54804a55615f"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "> ## From Freezer Burn to Fuel: My Meal Prep Journey\n> \n> Let's be honest, the image of a job interview can be pretty stressful.  But even more stressful than facing a panel of interviewers?  The gnawing hunger that strikes mid-interview! That's why my meal prep journey started – not with a cleanse or a weight loss goal, but with the simple desire to feel confident and energized, inside and out.\n> \n> This wasn't some Instagram-perfect transformation. It began with a lot of trial and error, a freezer full of freezer-burned concoctions, and more than a few disappointed sighs when my carefully planned lunch turned into a soggy mess.  But I persevered.  \n> \n> My initial attempts involved overly ambitious recipes and chaotic organization.  I would spend hours prepping food only to have it go bad before I could eat it. Then came the realization that keeping things simple and realistic was key.  I started small, focusing on building blocks like roasted chicken, quinoa, and a few different simple salad bases.   Then, I focused on portion control and effective storage.\n> \n> And the results?  I'm now a true meal-prep convert.  This week's lunch, for example, pictured here is a simple yet satisfying powerhouse: roasted chicken breast, a bed of mixed greens with a simple vinaigrette, and a generous helping of quinoa.  It's healthy, portable, and most importantly – delicious!  It fuels me for those high-stakes interviews (and everything else life throws at me).\n> \n> So, are you ready to ditch the soggy sandwiches and embrace the power of meal prepping? It's a journey, not a destination, and it's totally worth the effort.  Remember to start small, keep it simple, and most importantly, be kind to yourself along the way.  Your future self (and your interview performance) will thank you.\n"
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = model.generate_content([\"Generate an accurate caption for this image.\",img])\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "id": "b1dYRfzPWyn_",
        "outputId": "1486b071-6e96-4549-9ae7-c5506c263226"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Here's a caption for the image:\n",
            "\n",
            "**Option 1 (Concise):**\n",
            "\n",
            "> Mastering interview skills for success.\n",
            "\n",
            "**Option 2 (More descriptive):**\n",
            "\n",
            "> Ace your next job interview!  Practice makes perfect.  Develop strong interview skills to impress potential employers.\n",
            "\n",
            "**Option 3 (Focus on the image):**\n",
            "\n",
            "> A job interview in progress.  Notice the confident body language and preparedness of the candidates.  Learn the skills to succeed!\n",
            "\n",
            "\n",
            "Choose the option that best suits your needs and intended audience.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image_path ='/content/quote.jpg'\n",
        "image = Image.open(image_path)\n",
        "response = model.generate_content([\"Extraxt and reade the text from this image.\",image])\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "id": "T8o0yu0ueCiY",
        "outputId": "d033d1b5-20ee-4ee9-fc99-7fa280c96799"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FAILURE is not the\n",
            "opposite of success\n",
            "it's PART OF\n",
            "SUCCESS\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image_path ='/content/logo1.jpg'\n",
        "image = Image.open(image_path)\n",
        "response = model.generate_content([\"Extraxt and reade the text from this image.\",image])\n",
        "print(response.text)"
      ],
      "metadata": {
        "id": "t1LYyNjUeCe9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "caf708c0-1e6f-4318-81de-bd82dde9231b"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "amazon\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image_path = \"/content/product.jpg\"\n",
        "\n",
        "image = Image.open(image_path)\n",
        "\n",
        "model = genai.GenerativeModel('gemini-1.5-flash')\n",
        "\n",
        "response = model.generate_content([\"What product is shown in this image?\", image])\n",
        "\n",
        "print(response.text)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "RWu_4PIwNNic",
        "outputId": "9b2febfb-e388-42b9-a054-458612490cd1"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "That's a pair of black over-ear headphones.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as genai\n",
        "\n",
        "from google.colab import userdata\n",
        "\n",
        "GOOGLE_API_KEY=userdata.get('GOOGLE_API_KEY')\n",
        "\n",
        "genai.configure(api_key=GOOGLE_API_KEY)\n"
      ],
      "metadata": {
        "id": "iSBpx6Z6NNgW"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = model.generate_content([\"Suggest similar products to this one.\", image])\n",
        "\n",
        "print(response.text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        },
        "id": "X5k2PD0vNNdw",
        "outputId": "35fbc342-0681-4a9b-83f5-8e64e8f7aa21"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Here are some similar products to the pictured black over-ear headphones.  To give the best recommendations, I need more information about what aspects are most important to you.  However, I can suggest some general alternatives based on appearance:\n",
            "\n",
            "**Focusing on Style and Appearance:**\n",
            "\n",
            "* **Other over-ear headphones in a similar matte black color:**  Many brands offer sleek, black over-ear headphones with a similar design aesthetic. Search for \"matte black over-ear headphones\" on major online retailers.  Look at brands like Sony, Bose, Audio-Technica, Sennheiser, and JBL.\n",
            "\n",
            "**To give better suggestions, tell me:**\n",
            "\n",
            "* **What is your budget?** (e.g., under $50, $50-$100, $100-$200, over $200)\n",
            "* **What features are important to you?** (e.g., noise cancellation, wireless, long battery life, comfortable earcups, microphone quality, specific audio features like bass boost)\n",
            "* **What is your intended use?** (e.g., listening to music, gaming, calls, travel)\n",
            "\n",
            "Once I have this information, I can provide much more specific and helpful recommendations.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Open an image containing a price\n",
        "\n",
        "image_path = \"invoice.jpg\"  # Change to your image file\n",
        "\n",
        "image = Image.open(image_path)\n",
        "\n",
        "# Ask Gemini AI to extract the price\n",
        "\n",
        "response = model.generate_content([\"Extract the price from this image.\", image])\n",
        "\n",
        "print(response.text)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "JB_mp3uTNNa8",
        "outputId": "cc98dbfd-031a-4bd8-d42b-34b78a94f1d9"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The price on the invoice is $100.00.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = model.generate_content([\"Extract the price, currency, and any discounts from this image.\", image])\n",
        "\n",
        "print(response.text)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "id": "wKCPfovoNNYL",
        "outputId": "19541147-12a4-431e-d97a-183a1ce07bec"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Here's the extracted information from the image:\n",
            "\n",
            "* **Price:** $10.00 (per item)\n",
            "* **Currency:** USD ($)\n",
            "* **Discounts:** No discounts are listed.  There is a 10% tax, which is an increase, not a decrease in the price.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image_path = \"/content/bicycle.jpg\"\n",
        "image = Image.open(image_path)\n",
        "\n",
        "# Ask Gemini AI to extract the price\n",
        "\n",
        "response = model.generate_content([\"Identify all  objects present in this image.\", image])\n",
        "\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "id": "omsb0IfeNNVg",
        "outputId": "49d56dca-c909-4148-d310-351798b353c1"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Here are the objects present in the image:\n",
            "\n",
            "* **Two bicycles:** One is predominantly black and yellow, and the other is white.  Both appear to be mountain bikes or hybrid bikes.\n",
            "* **Two men:**  They are riding the bicycles. One is wearing a blue shirt and camouflage shorts, the other is wearing a grey shirt and blue jeans and a red cap.\n",
            "* **A motorcycle:** Parked on the left side of the image.\n",
            "* **A building:**  A building with a shop front, including a roll-up door, a window, and some items visible inside the shop.\n",
            "* **Two chairs:**  Visible inside the building's entrance.\n",
            "* **A man:**  Standing inside the building; appears to be watching the cyclists.\n",
            "* **Street:** The street is wet, suggesting recent rain.\n",
            "* **Vegetation:**  Some grass and weeds are visible along the edge of the street.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image_path = \"/content/items.jpg\"\n",
        "image = Image.open(image_path)\n",
        "\n",
        "# Ask Gemini AI to extract the price\n",
        "\n",
        "response = model.generate_content([\"List all objects in this image and count how many of each are present .\", image])\n",
        "\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 503
        },
        "id": "xodUjKuUNNRX",
        "outputId": "bb2bbc82-419c-48e4-b329-09ed394dbfcd"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Here's a count of the objects in the image:\n",
            "\n",
            "**Countables:**\n",
            "\n",
            "* Eggs: 3\n",
            "* Banana: 1\n",
            "* Olives: 2\n",
            "* Fries: 1 (serving)\n",
            "* Burger: 1\n",
            "* Hot dog: 1\n",
            "* Apple: 1\n",
            "* Carrots: 2\n",
            "* Tomatoes: 3\n",
            "* Watermelon: 1\n",
            "\n",
            "\n",
            "**Uncountables:**\n",
            "\n",
            "* Milk: 1 (container)\n",
            "* Flour: 1 (bag)\n",
            "* Salt: 1 (container)\n",
            "* Sugar: 1 (container)\n",
            "* Jam: 1 (jar)\n",
            "* Meat: 2 (slices)\n",
            "* Rice: 1 (bowl)\n",
            "* Honey: 1 (jar)\n",
            "* Tea: 1 (cup)\n",
            "* Cheese: 1 (slice)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install youtube-transcript-api pytube\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XTMZUXkwTRQ6",
        "outputId": "0b3333a4-ce3a-40f3-d980-c0b95b087aa2"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting youtube-transcript-api\n",
            "  Downloading youtube_transcript_api-1.0.1-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting pytube\n",
            "  Downloading pytube-15.0.0-py3-none-any.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: defusedxml<0.8.0,>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from youtube-transcript-api) (0.7.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from youtube-transcript-api) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->youtube-transcript-api) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->youtube-transcript-api) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->youtube-transcript-api) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->youtube-transcript-api) (2025.1.31)\n",
            "Downloading youtube_transcript_api-1.0.1-py3-none-any.whl (1.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m24.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytube-15.0.0-py3-none-any.whl (57 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pytube, youtube-transcript-api\n",
            "Successfully installed pytube-15.0.0 youtube-transcript-api-1.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from youtube_transcript_api import YouTubeTranscriptApi\n",
        "\n",
        "def get_youtube_transcript(video_url):\n",
        "\n",
        "    \"\"\"Fetches the transcript of a YouTube video.\"\"\"\n",
        "\n",
        "    video_id = video_url.split(\"v=\")[1].split(\"&\")[0]  # Extract video ID\n",
        "\n",
        "    transcript = YouTubeTranscriptApi.get_transcript(video_id)\n",
        "\n",
        "    full_text = \" \".join([t[\"text\"] for t in transcript])\n",
        "\n",
        "    return full_text\n",
        "\n",
        "# Example Usage\n",
        "\n",
        "video_url = \"https://www.youtube.com/watch?v=unYDoA8QGH0&list=PLWEpztHwA4ZT2QlHC74oIz4MsawcvE-QX\"\n",
        "\n",
        "video_transcript = get_youtube_transcript(video_url)\n",
        "\n",
        "print(\"Transcript:\\n\", video_transcript[:500])  # Show first 500 characters\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ISSNX2iyTRNh",
        "outputId": "15820584-4f4f-4b41-dd76-2e9724d8a2e2"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcript:\n",
            " hi guys today I'm going to introduce you what is machine learning uh these are my presentation content what is machine learning what are the different applications of machine learning different types of machine learning and how to build a machine learning system or model then various kinds of algorithms and later on in this series we are going to take a Hands-On you know case studies or doing programming for various kinds of up algorithms so what is machine learning so machine learning is nothin\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Configure Gemini API\n",
        "\n",
        "import google.generativeai as genai\n",
        "\n",
        "from google.colab import userdata\n",
        "\n",
        "GOOGLE_API_KEY=userdata.get('GOOGLE_API_KEY')\n",
        "\n",
        "genai.configure(api_key=GOOGLE_API_KEY)\n"
      ],
      "metadata": {
        "id": "HsmSOgGyVyhN"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def summarize_video(text):\n",
        "\n",
        "    \"\"\"Summarizes the YouTube video transcript using Gemini AI.\"\"\"\n",
        "\n",
        "    model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
        "\n",
        "    prompt = f\"Summarize the following YouTube video transcript:\\n\\n{text}\"\n",
        "\n",
        "    response = model.generate_content(prompt)\n",
        "\n",
        "    return response.text\n",
        "\n",
        "summary = summarize_video(video_transcript)\n",
        "\n",
        "print(\"Summary:\\n\", summary)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        },
        "id": "EdWIAAfUVyVG",
        "outputId": "ccb01e9a-e495-4383-9602-5f595b7881a1"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summary:\n",
            " This YouTube video introduces machine learning, covering its definition, applications, types, and the process of building a machine learning model.  Machine learning is defined as learning from data, a subfield of AI enabling smarter applications.  The video highlights applications in speech recognition, web search, recommendation systems, computer vision, information retrieval, and fraud detection.\n",
            "\n",
            "Three main types of machine learning are discussed: supervised (learning from labeled data, including classification and regression), unsupervised (learning from unlabeled data, such as clustering and dimensionality reduction), and reinforcement learning (learning through trial and error with rewards and penalties).\n",
            "\n",
            "The video details the process of building a machine learning model, emphasizing data preprocessing (cleaning, scaling, encoding, feature selection), algorithm selection (different algorithms for classification and regression), model building, and evaluation.  The presenter promises future videos with hands-on case studies and programming examples of various algorithms, specifically focusing on the Iris dataset as a practical example.  Key terminology like features, attributes, samples, target variables, and the workflow of a machine learning pipeline are also explained.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_video_insights(text):\n",
        "\n",
        "    \"\"\"Extracts key insights from the YouTube video transcript.\"\"\"\n",
        "\n",
        "    model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
        "\n",
        "    prompt = f\"Extract the key takeaways and insights from this YouTube video:\\n\\n{text}\"\n",
        "\n",
        "    response = model.generate_content(prompt)\n",
        "\n",
        "    return response.text\n",
        "\n",
        "insights = extract_video_insights(video_transcript)\n",
        "\n",
        "print(\"Key Insights:\\n\", insights)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 852
        },
        "id": "Z936aEDhVyIg",
        "outputId": "05114356-69a1-495c-b295-5a1de7d843fe"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Key Insights:\n",
            " This YouTube video provides an introduction to machine learning. Here are the key takeaways and insights:\n",
            "\n",
            "**What is Machine Learning?**\n",
            "\n",
            "* **Learning from Data:**  Machine learning is essentially learning from data.  It's a subfield of AI that allows systems to learn from experience (data) without explicit programming.  This learning process results in a model that can make predictions on new, unseen data.\n",
            "* **Arthur Samuel's Definition:** The video highlights Arthur Samuel's definition:  a field of study that gives computers the ability to learn without being explicitly programmed.\n",
            "* **The Learning Process:** The process involves using training data (past data) to build a model using a machine learning algorithm.  This model is then used to predict future outcomes.\n",
            "* **Types of Machine Learning:** The video focuses on three main types:\n",
            "    * **Supervised Learning:** The training data is labeled (the desired outcome is known), used for classification (predicting categories) and regression (predicting continuous values).\n",
            "    * **Unsupervised Learning:** The training data is unlabeled, used for tasks like clustering (grouping similar data points) and dimensionality reduction (reducing the number of variables).\n",
            "    * **Reinforcement Learning:**  An agent learns by interacting with an environment, receiving rewards for good actions and penalties for bad ones.  This is commonly used in game playing and robotics.\n",
            "\n",
            "**Applications of Machine Learning:**\n",
            "\n",
            "The video lists several applications, showcasing its broad applicability:\n",
            "\n",
            "* **Speech Recognition:**  Powering virtual assistants like Siri and Google Assistant.\n",
            "* **Web Search:** Improving search engine results using algorithms like Naive Bayes.\n",
            "* **Recommendation Systems:** Suggesting products or content based on user preferences.\n",
            "* **Computer Vision:** Enabling computers to \"see\" and understand images and videos.\n",
            "* **Information Retrieval:** Enhancing search capabilities across vast datasets.\n",
            "* **Fraud Detection:** Identifying malicious activities.\n",
            "\n",
            "\n",
            "**Building a Machine Learning Model:**\n",
            "\n",
            "The video outlines the typical workflow:\n",
            "\n",
            "1. **Data Preprocessing:** Cleaning and preparing the data (handling missing values, scaling features, encoding categorical variables, feature selection, dimensionality reduction).\n",
            "2. **Algorithm Selection:** Choosing an appropriate algorithm (e.g., decision tree, random forest, K-nearest neighbors) based on the problem type (classification or regression).\n",
            "3. **Model Building:** Applying the chosen algorithm to the training data to create a predictive model.\n",
            "4. **Model Evaluation:** Assessing the model's accuracy and performance using metrics.  The video emphasizes building multiple models for comparison.\n",
            "\n",
            "**Key Terms:**\n",
            "\n",
            "The video defines several crucial machine learning terms:\n",
            "\n",
            "* **Features/Attributes:**  The variables in the dataset used to make predictions.\n",
            "* **Target Variable/Response Variable:** The variable being predicted.\n",
            "* **Samples/Instances/Observations:** The rows in the dataset (individual data points).\n",
            "* **Training Data:** The data used to train the model.\n",
            "* **Model:** The output of the machine learning algorithm, used for prediction.\n",
            "\n",
            "\n",
            "**Overall:** The video serves as a good high-level introduction to machine learning, covering its core concepts, types, applications, and the general process of building a model.  It sets the stage for more in-depth exploration of specific algorithms and techniques in future videos.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def ask_question_about_video(text, question):\n",
        "\n",
        "    \"\"\"Answers user questions about the YouTube video content.\"\"\"\n",
        "\n",
        "    model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
        "\n",
        "    prompt = f\"The following is a YouTube video transcript:\\n\\n{text}\\n\\nAnswer this question based on the content:\\n{question}\"\n",
        "\n",
        "    response = model.generate_content(prompt)\n",
        "\n",
        "    return response.text\n",
        "\n",
        "question = \"What is the main topic discussed in the video?\"\n",
        "\n",
        "answer = ask_question_about_video(video_transcript, question)\n",
        "\n",
        "print(\"Answer:\\n\", answer)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "id": "VdMgbuzZWHzf",
        "outputId": "12f71447-f013-41fb-aa60-6a498e7fb221"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer:\n",
            " The main topic of the YouTube video is an introduction to machine learning.  The video covers what machine learning is, its applications, different types of machine learning (supervised, unsupervised, and reinforcement learning),  how to build a machine learning model (including data preprocessing steps), and various algorithms used.  The presenter also mentions future videos will delve into hands-on case studies and programming aspects.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def analyze_sentiment(text):\n",
        "\n",
        "    \"\"\"Performs sentiment analysis on the YouTube video transcript.\"\"\"\n",
        "\n",
        "    model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
        "\n",
        "    prompt = f\"Analyze the sentiment of this YouTube video transcript. Is it positive, negative, or neutral?\\n\\n{text}\"\n",
        "\n",
        "    response = model.generate_content(prompt)\n",
        "\n",
        "    return response.text\n",
        "\n",
        "sentiment = analyze_sentiment(video_transcript)\n",
        "\n",
        "print(\"Sentiment Analysis:\\n\", sentiment)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "id": "m5wIdafEWHq5",
        "outputId": "34acfcc1-33a9-4655-ac4d-df319fcc7a82"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentiment Analysis:\n",
            " The sentiment of the YouTube video transcript is overwhelmingly **positive**.  The speaker is enthusiastic and encouraging, using phrases like \"very smarter applications,\" \"growing a lot,\" and \"very good.\"  The tone is instructional and optimistic, focusing on the exciting possibilities of machine learning and offering a clear, structured path for learning the subject.  While there's no explicitly positive emotional language, the overall message is one of hope and empowerment regarding the potential of machine learning.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "b6b6DxHxXxs3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "297hUXwqXxp4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}